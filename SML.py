from segmentation_models import Unet, Nestnet, Xnet
import numpy as np
from keras import backend as K
from keras.models import Model
from keras.layers import Flatten, Dense, Dropout
from keras.applications.resnet50 import ResNet50, preprocess_input
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import os
import sys
import cv2


# prepare data

DATASET_PATH  = '/home/dhruv/Allprojects/NIH-XRAY'
IMAGE_SIZE    = (256, 256)
CROP_LENGTH   = 224
NUM_CLASSES   = 2
BATCH_SIZE    = 8  # try reducing batch size or freeze more layers if your GPU runs out of memory
FREEZE_LAYERS = 2  # freeze the first this many layers for training
NUM_EPOCHS    = 20
WEIGHTS_FINAL = 'model-cropped-final.h5'


def bgr_to_rgb(bgr):
    rgb = bgr[...,::-1]
    return rgb

def rgb_to_bgr(rgb):
    bgr = rgb[...,::-1]
    return bgr

def plot_bgr(img):
    plt.imshow(bgr_to_rgb(img))

def plot_rgb(img):
    plt.imshow(img)

def plot_gray(img):
    # img could be either (H,W) or (H,W,C)
    if len(img.shape) == 2:
        plt.imshow(img, cmap='gray')
    else:
        plt.imshow(img)

def plots(ims, is_bgr=True, figsize=(12,6), rows=1, interp=False, titles=None):
    ndims = len(ims[0].shape)
    assert ndims == 3 or ndims == 2
    if ndims == 2:  # convert grayscale images to bgr
        ims = [cv2.cvtColor(img, cv2.COLOR_GRAY2BGR) for img in ims]
    ims = np.array(ims).astype(np.uint8)
    if (ims.shape[-1] != 3):
        ims = ims.transpose((0,2,3,1))
    f = plt.figure(figsize=figsize)
    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1
    for i in range(len(ims)):
        sp = f.add_subplot(rows, cols, i+1)
        sp.axis('Off')
        if titles is not None:
            sp.set_title(titles[i], fontsize=16)
        if is_bgr:
            plt.imshow(bgr_to_rgb(ims[i]), interpolation=None if interp else 'none')
        else:
            plt.imshow(ims[i], interpolation=None if interp else 'none')


def crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    # assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy0, dx0 = 836
    x0 = 94
    y0 = 45
    return img[y0:(y0+dy0), x0:(x0+dx0), :]
    # plt.imshow('image',img[y0:(y0+dy0), x0:(x0+dx0), :])
    # plt.show()


def random_crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    # assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy0, dx0 = 836
    x0 = 94
    y0 = 45
    img=img[y0:(y0+dy0), x0:(x0+dx0), :]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    return img[y:(y+dy), x:(x+dx), :]
    # print("yoloa")
    # plt.imshow('crop_image',img[y0:(y0+dy0), x0:(x0+dx0), :])
    # plt.show()


def crop_generator(batches, crop_length):
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """
    while True:
        batch_x, batch_y = next(batches)
        batch_crops_inp = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        batch_crops_tar = np.zeros((batch_x.shape[0], crop_length, crop_length, 3))
        for i in range(batch_x.shape[0]):
            batch_crops_inp[i] = random_crop(batch_x[i], (crop_length, crop_length))
            batch_crops_tar[i] = crop(batch_x[i], (crop_length, crop_length))
        yield (batch_crops_inp, batch_crops_tar)


train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,
                                   fill_mode='nearest')
train_batches = train_datagen.flow_from_directory(DATASET_PATH + '/train',
                                                  target_size=IMAGE_SIZE,
                                                  interpolation='bicubic',
                                                  class_mode='input',
                                                  shuffle=True)

valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
valid_batches = valid_datagen.flow_from_directory(DATASET_PATH + '/validation',
                                                  target_size=IMAGE_SIZE,
                                                  interpolation='bicubic',
                                                  class_mode='input',
                                                  shuffle=False)

train_crops = crop_generator(train_batches, CROP_LENGTH)
valid_crops = crop_generator(valid_batches, CROP_LENGTH)



batch_x, batch_y = next(train_crops)
batch_x.shape

# prepare model

pixel_mean = np.array([103.939, 116.779, 123.68]).reshape((1,1,3))
plots([batch_x[i]+pixel_mean for i in range(batch_x.shape[0])], rows = 2)
#model = Xnet(backbone_name='resnet50', encoder_weights='imagenet', decoder_block_type='transpose') # build UNet++
#model = Unet(backbone_name='resnet18', encoder_weights='imagenet', decoder_block_type='transpose') # build U-Net
# model = NestNet(backbone_name='resnet50', encoder_weights='imagenet', decoder_block_type='transpose') # build DLA


#model.compile('Adam', 'binary_crossentropy', ['binary_accuracy'])

# train model
# model.fit_generator(train_crops,
#                         steps_per_epoch = train_batches.samples // BATCH_SIZE,
#                         validation_data = valid_crops,
#                         validation_steps = valid_batches.samples // BATCH_SIZE,
#                         epochs = 100)