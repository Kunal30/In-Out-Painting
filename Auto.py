"""
This script goes along my blog post:
Extending Keras' ImageDataGenerator to Support Random Cropping (https://jkjung-avt.github.io/keras-image-cropping/)
"""

from segmentation_models import Unet, Nestnet, Xnet

import numpy as np
from keras import backend as K
from keras.models import Model
from keras.layers import Flatten, Dense, Dropout
from keras.applications.resnet50 import ResNet50, preprocess_input
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator
import os
import sys

import numpy as np
from matplotlib import pyplot as plt
import cv2

DATASET_PATH  = '/home/dhruv/Allprojects/NIH-XRAY'
IMAGE_SIZE    = (256, 256)
CROP_LENGTH   = 836
NUM_CLASSES   = 2
BATCH_SIZE    = 32  # try reducing batch size or freeze more layers if your GPU runs out of memory
FREEZE_LAYERS = 2  # freeze the first this many layers for training
NUM_EPOCHS    = 20
WEIGHTS_FINAL = 'model-cropped-final.h5'



def random_crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    height, width = img.shape[0], img.shape[1]
    dy, dx = random_crop_size
    x = np.random.randint(0, width - dx + 1)
    y = np.random.randint(0, height - dy + 1)
    img=img[y:(y+dy), x:(x+dx), :]
    img = cv2.resize(img,(224,224))
    # cv2.imshow("img",img)
    return img


def crop(img, random_crop_size):
    # Note: image_data_format is 'channel_last'
    # assert img.shape[2] == 3
    height, width = img.shape[0], img.shape[1]
    dy0, dx0 = 836,836
    x0 = 94
    y0 = 45
    img=img[y0:(y0+dy0), x0:(x0+dx0), :]
    img = cv2.resize(img,(224,224))
    # cv2.imshow("img",img)
    return img

def crop_generator(batches, crop_length):#224
    """Take as input a Keras ImageGen (Iterator) and generate random
    crops from the image batches generated by the original iterator.
    """
    while True:
        batch_x= next(batches)
        # cv2.imshow("yolo",batch_)
        batch_crops_inp = np.zeros((batch_x.shape[0], 224, 224,3))#224
        batch_crops_tar = np.zeros((batch_x.shape[0], 224, 224,3))
        for i in range(batch_x.shape[0]):
            batch_crops_inp[i] = random_crop(batch_x[i], (crop_length, crop_length))
            batch_crops_tar[i] = crop(batch_x[i], (crop_length, crop_length))
        yield (batch_crops_inp,batch_crops_tar)


train_datagen = ImageDataGenerator(rescale=1/255)
train_batches = train_datagen.flow_from_directory(DATASET_PATH,
                                                  target_size=(1024,1024),
                                                  shuffle=True,
                                                  class_mode=None,
                                                  batch_size=BATCH_SIZE)

valid_datagen = ImageDataGenerator(rescale=1/255)
valid_batches = valid_datagen.flow_from_directory(DATASET_PATH ,
                                                  target_size=(1024,1024),
                                                  shuffle=False,
                                                  class_mode=None,
                                                  batch_size=BATCH_SIZE)
train_crops = crop_generator(train_batches, CROP_LENGTH) #224
valid_crops = crop_generator(valid_batches, CROP_LENGTH)




batch_x, batch_y = next(train_crops)
print (np.array(batch_x).shape)
print (np.array(batch_y).shape)
plt.imshow(batch_x[0])
plt.show()
plt.imshow(batch_y[0])
plt.show()
# build our classifier model based on pre-trained ResNet50:
# 1. we don't include the top (fully connected) layers of ResNet50
# 2. we add a DropOut layer followed by a Dense (fully connected)
#    layer which generates softmax class score for each class
# 3. we compile the final model using an Adam optimizer, with a
#    low learning rate (since we are 'fine-tuning')
model = Unet(backbone_name='resnet18', encoder_weights='imagenet', decoder_block_type='transpose') # build U-Net
model.compile('Adam', 'binary_crossentropy', ['binary_accuracy'])

model.fit_generator(generator=train_crops,
                    steps_per_epoch=12,
                    validation_data=valid_crops,
                    validation_steps=12,
                    epochs=100)
